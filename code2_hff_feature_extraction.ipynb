{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.feature import hog, local_binary_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HFF CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Pdogg Windows10\\.cache\\huggingface\\hub\\models--timm--seresnet50.a1_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Pdogg Windows10\\.cache\\huggingface\\hub\\models--timm--resnext50_32x4d.a1h_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Pdogg Windows10\\.cache\\huggingface\\hub\\models--timm--resnest50d.in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Define image size\n",
    "image_size = (224, 224)  # Suitable for ResNet, DenseNet, and similar architectures\n",
    "\n",
    "# Define supported models\n",
    "cnn_models = {\n",
    "    'ResNet-50': models.resnet50(pretrained=True),\n",
    "    'SE-ResNet-50': timm.create_model('seresnet50', pretrained=True),\n",
    "    'ResNeXt-50': timm.create_model('resnext50_32x4d', pretrained=True),\n",
    "    'ResNeSt-50': timm.create_model('resnest50d', pretrained=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Data224/train'\n",
    "test_dir = 'Data224/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transformations (Same for all CNN models)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the selected model and remove the last layer\n",
    "def load_cnn_model(model_name):\n",
    "    if model_name not in cnn_models:\n",
    "        raise ValueError(f\"Model '{model_name}' not found in supported models!\")\n",
    "\n",
    "    model = cnn_models[model_name]\n",
    "    model = nn.Sequential(*list(model.children())[:-1])  # Remove last FC layer\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract CNN features\n",
    "def extract_cnn_features(image, model):\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.flatten().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract handcrafted features (HOG, LBP, Color Histogram)\n",
    "def extract_handcrafted_features(image):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # HOG Feature Extraction\n",
    "    hog_features = hog(image_gray, pixels_per_cell=(16, 16), cells_per_block=(1, 1), feature_vector=True)\n",
    "\n",
    "    # LBP Feature Extraction\n",
    "    lbp = local_binary_pattern(image_gray, P=24, R=3, method=\"uniform\")\n",
    "    lbp_hist, _ = np.histogram(lbp, bins=np.arange(0, 27), density=True)\n",
    "\n",
    "    # Color Histogram (RGB)\n",
    "    hist_r = cv2.calcHist([image], [0], None, [256], [0, 256]).flatten()\n",
    "    hist_g = cv2.calcHist([image], [1], None, [256], [0, 256]).flatten()\n",
    "    hist_b = cv2.calcHist([image], [2], None, [256], [0, 256]).flatten()\n",
    "\n",
    "    # Normalize and concatenate features\n",
    "    hist_rgb = np.concatenate([hist_r, hist_g, hist_b]) / np.linalg.norm(hist_r)\n",
    "    \n",
    "    return np.concatenate([hog_features, lbp_hist, hist_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process dataset (train or test) using a specific CNN model\n",
    "def process_dataset(dataset_dir, dataset_type, model_name):\n",
    "    # Load the selected model\n",
    "    model = load_cnn_model(model_name)\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_mapping = {}\n",
    "    class_id = 0\n",
    "\n",
    "    # Define save directory\n",
    "    save_dir = os.path.join(\"features\", model_name, dataset_type)\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "    for class_folder in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-directory files\n",
    "\n",
    "        if class_folder not in class_mapping:\n",
    "            class_mapping[class_folder] = class_id\n",
    "            class_id += 1\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Skipping invalid image: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Extract CNN and Handcrafted Features\n",
    "            resnet_feat = extract_cnn_features(Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)), model)\n",
    "            handcrafted_feat = extract_handcrafted_features(image)\n",
    "            \n",
    "            # Combine both feature sets\n",
    "            combined_features = np.concatenate([resnet_feat, handcrafted_feat])\n",
    "\n",
    "            features.append(combined_features)\n",
    "            labels.append(class_mapping[class_folder])\n",
    "\n",
    "     # Convert to NumPy arrays and save\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    np.save(os.path.join(save_dir, f\"hff_features_{dataset_type}.npy\"), features)\n",
    "    np.save(os.path.join(save_dir, f\"hff_labels_{dataset_type}.npy\"), labels)\n",
    "    \n",
    "    print(f\"✅ {dataset_type.capitalize()} Feature Extraction Completed for {model_name}! Extracted {features.shape[1]} features per image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train Feature Extraction Completed for DenseNet-121! Extracted 52734 features per image.\n",
      "✅ Test Feature Extraction Completed for DenseNet-121! Extracted 52734 features per image.\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_dir, \"train\", \"DenseNet-121\")\n",
    "process_dataset(test_dir, \"test\", \"DenseNet-121\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE-ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train Feature Extraction Completed for SE-ResNet-50! Extracted 4606 features per image.\n",
      "✅ Test Feature Extraction Completed for SE-ResNet-50! Extracted 4606 features per image.\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_dir, \"train\", \"SE-ResNet-50\")\n",
    "process_dataset(test_dir, \"test\", \"SE-ResNet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNext-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train Feature Extraction Completed for ResNeXt-50! Extracted 4606 features per image.\n",
      "✅ Test Feature Extraction Completed for ResNeXt-50! Extracted 4606 features per image.\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_dir, \"train\", \"ResNeXt-50\")\n",
    "process_dataset(test_dir, \"test\", \"ResNeXt-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNeSt-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train Feature Extraction Completed for ResNeSt-50! Extracted 4606 features per image.\n",
      "✅ Test Feature Extraction Completed for ResNeSt-50! Extracted 4606 features per image.\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_dir, \"train\", \"ResNeSt-50\")\n",
    "process_dataset(test_dir, \"test\", \"ResNeSt-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "majorproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
