{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "train_dir = \"Dataset_Final/Train\"\n",
    "test_dir = \"Dataset_Final/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check images in a directory\n",
    "def check_images(directory):\n",
    "    image_sizes = defaultdict(int)\n",
    "    invalid_images = []\n",
    "    class_distribution = defaultdict(int)\n",
    "\n",
    "    for class_folder in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_folder)\n",
    "        \n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-directory files\n",
    "        \n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            # Read image using OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is None:\n",
    "                invalid_images.append(img_path)\n",
    "                continue\n",
    "            \n",
    "            height, width, _ = img.shape\n",
    "            image_sizes[(width, height)] += 1\n",
    "            class_distribution[class_folder] += 1\n",
    "\n",
    "    return image_sizes, invalid_images, class_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train Dataset Checks ---\n",
      "Unique Image Sizes: defaultdict(<class 'int'>, {(300, 300): 1268, (480, 640): 4269, (640, 480): 2, (1200, 1600): 271, (224, 224): 3393, (1600, 1200): 13, (1200, 929): 1, (1200, 949): 1, (455, 607): 1, (720, 1600): 2, (4000, 3000): 2, (1000, 469): 1, (1269, 1200): 1, (390, 1270): 1, (3000, 4000): 3, (1283, 962): 1, (438, 1074): 1, (1185, 693): 1, (2448, 3264): 7, (589, 786): 1, (778, 1037): 1, (761, 810): 1, (1046, 1200): 1, (1203, 1200): 1, (1106, 830): 1, (1018, 763): 1})\n",
      "Corrupt Images: []\n",
      "Class Distribution: defaultdict(<class 'int'>, {'BacterialBlight': 1268, 'BacterialLeafBlight': 1200, 'BacterialLeafStreak': 1200, 'Blast': 1391, 'BrownSpot': 1200, 'Normal': 1786, 'SheathBlight': 1201})\n",
      "\n",
      "--- Test Dataset Checks ---\n",
      "Unique Image Sizes: defaultdict(<class 'int'>, {(300, 300): 316, (480, 640): 1053, (640, 480): 2, (224, 224): 869, (1200, 1600): 62, (1600, 1200): 2, (1200, 1072): 1, (829, 966): 1, (1200, 823): 1, (570, 760): 1})\n",
      "Corrupt Images: []\n",
      "Class Distribution: defaultdict(<class 'int'>, {'BacterialBlight': 316, 'BacterialLeafBlight': 300, 'BacterialLeafStreak': 300, 'Blast': 347, 'BrownSpot': 300, 'Normal': 446, 'SheathBlight': 299})\n",
      "\n",
      "⚠️ Warning: Images have inconsistent sizes. Consider resizing before training.\n"
     ]
    }
   ],
   "source": [
    "# Run checks on train and test sets\n",
    "train_sizes, train_invalids, train_classes = check_images(train_dir)\n",
    "test_sizes, test_invalids, test_classes = check_images(test_dir)\n",
    "\n",
    "# Print Results\n",
    "print(\"\\n--- Train Dataset Checks ---\")\n",
    "print(\"Unique Image Sizes:\", train_sizes)\n",
    "print(\"Corrupt Images:\", train_invalids)\n",
    "print(\"Class Distribution:\", train_classes)\n",
    "\n",
    "print(\"\\n--- Test Dataset Checks ---\")\n",
    "print(\"Unique Image Sizes:\", test_sizes)\n",
    "print(\"Corrupt Images:\", test_invalids)\n",
    "print(\"Class Distribution:\", test_classes)\n",
    "\n",
    "# If images are not the same size, suggest resizing them\n",
    "if len(train_sizes) > 1 or len(test_sizes) > 1:\n",
    "    print(\"\\n⚠️ Warning: Images have inconsistent sizes. Consider resizing before training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base_dir = \"Data224\"  \n",
    "if not os.path.exists(output_base_dir):\n",
    "    os.makedirs(output_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save_images(source_dir, target_dir, target_size=(224, 224)):\n",
    "    os.makedirs(target_dir, exist_ok=True)  # Create target directory if it doesn't exist\n",
    "\n",
    "    for class_folder in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_folder)\n",
    "        target_class_path = os.path.join(target_dir, class_folder)\n",
    "\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-directory files\n",
    "\n",
    "        os.makedirs(target_class_path, exist_ok=True)  # Create class folder in target directory\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            target_img_path = os.path.join(target_class_path, img_file)\n",
    "\n",
    "            # Read image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Skipping corrupt image: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            # Resize image\n",
    "            resized_img = cv2.resize(img, target_size)\n",
    "\n",
    "            # Save image in new folder\n",
    "            cv2.imwrite(target_img_path, resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All images resized and saved in 'Data/' successfully!\n"
     ]
    }
   ],
   "source": [
    "# Resize train and test images\n",
    "resize_and_save_images(train_dir, os.path.join(output_base_dir, \"train\"))\n",
    "resize_and_save_images(test_dir, os.path.join(output_base_dir, \"test\"))\n",
    "\n",
    "print(\"✅ All images resized and saved in 'Data/' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_dir = \"Data224/train\"\n",
    "new_test_dir = \"Data224/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train Dataset Checks ---\n",
      "Unique Image Sizes: defaultdict(<class 'int'>, {(224, 224): 9246})\n",
      "Corrupt Images: []\n",
      "Class Distribution: defaultdict(<class 'int'>, {'BacterialBlight': 1268, 'BacterialLeafBlight': 1200, 'BacterialLeafStreak': 1200, 'Blast': 1391, 'BrownSpot': 1200, 'Normal': 1786, 'SheathBlight': 1201})\n",
      "\n",
      "--- Test Dataset Checks ---\n",
      "Unique Image Sizes: defaultdict(<class 'int'>, {(224, 224): 2308})\n",
      "Corrupt Images: []\n",
      "Class Distribution: defaultdict(<class 'int'>, {'BacterialBlight': 316, 'BacterialLeafBlight': 300, 'BacterialLeafStreak': 300, 'Blast': 347, 'BrownSpot': 300, 'Normal': 446, 'SheathBlight': 299})\n"
     ]
    }
   ],
   "source": [
    "# Run checks on train and test sets\n",
    "train_sizes, train_invalids, train_classes = check_images(new_train_dir)\n",
    "test_sizes, test_invalids, test_classes = check_images(new_test_dir)\n",
    "\n",
    "# Print Results\n",
    "print(\"\\n--- Train Dataset Checks ---\")\n",
    "print(\"Unique Image Sizes:\", train_sizes)\n",
    "print(\"Corrupt Images:\", train_invalids)\n",
    "print(\"Class Distribution:\", train_classes)\n",
    "\n",
    "print(\"\\n--- Test Dataset Checks ---\")\n",
    "print(\"Unique Image Sizes:\", test_sizes)\n",
    "print(\"Corrupt Images:\", test_invalids)\n",
    "print(\"Class Distribution:\", test_classes)\n",
    "\n",
    "# If images are not the same size, suggest resizing them\n",
    "if len(train_sizes) > 1 or len(test_sizes) > 1:\n",
    "    print(\"\\n⚠️ Warning: Images have inconsistent sizes. Consider resizing before training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HFF Based Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"Data224/train\"\n",
    "test_dir = \"Data224/test\"\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Pdogg Windows10\\Desktop\\Semester 7\\IT499 - Major Project II\\Project\\majorproject\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Pretrained ResNet50\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model = nn.Sequential(*list(resnet_model.children())[:-1])  # Remove last FC layer\n",
    "resnet_model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transformations for ResNet50\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract ResNet features\n",
    "def extract_resnet_features(image):\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(image)\n",
    "    return features.flatten().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract handcrafted features (HOG, LBP, Color Histogram)\n",
    "def extract_handcrafted_features(image):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # HOG Feature Extraction\n",
    "    hog_features = hog(image_gray, pixels_per_cell=(16, 16), cells_per_block=(1, 1), feature_vector=True)\n",
    "\n",
    "    # LBP Feature Extraction\n",
    "    lbp = local_binary_pattern(image_gray, P=24, R=3, method=\"uniform\")\n",
    "    lbp_hist, _ = np.histogram(lbp, bins=np.arange(0, 27), density=True)\n",
    "\n",
    "    # Color Histogram (RGB)\n",
    "    hist_r = cv2.calcHist([image], [0], None, [256], [0, 256]).flatten()\n",
    "    hist_g = cv2.calcHist([image], [1], None, [256], [0, 256]).flatten()\n",
    "    hist_b = cv2.calcHist([image], [2], None, [256], [0, 256]).flatten()\n",
    "\n",
    "    # Normalize and concatenate features\n",
    "    hist_rgb = np.concatenate([hist_r, hist_g, hist_b]) / np.linalg.norm(hist_r)\n",
    "    \n",
    "    return np.concatenate([hog_features, lbp_hist, hist_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process dataset (train or test)\n",
    "def process_dataset(dataset_dir, dataset_type):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_mapping = {}\n",
    "    class_id = 0\n",
    "\n",
    "    for class_folder in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-directory files\n",
    "\n",
    "        if class_folder not in class_mapping:\n",
    "            class_mapping[class_folder] = class_id\n",
    "            class_id += 1\n",
    "\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Skipping invalid image: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Extract ResNet and Handcrafted Features\n",
    "            resnet_feat = extract_resnet_features(Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)))\n",
    "            handcrafted_feat = extract_handcrafted_features(image)\n",
    "            \n",
    "            # Combine both feature sets\n",
    "            combined_features = np.concatenate([resnet_feat, handcrafted_feat])\n",
    "\n",
    "            features.append(combined_features)\n",
    "            labels.append(class_mapping[class_folder])\n",
    "\n",
    "    # Convert to NumPy arrays and save\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    np.save(f\"hff_features_{dataset_type}.npy\", features)\n",
    "    np.save(f\"hff_labels_{dataset_type}.npy\", labels)\n",
    "    \n",
    "    print(f\"✅ {dataset_type.capitalize()} Feature Extraction Completed! Extracted {features.shape[1]} features per image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train Feature Extraction Completed! Extracted 4606 features per image.\n",
      "✅ Test Feature Extraction Completed! Extracted 4606 features per image.\n"
     ]
    }
   ],
   "source": [
    "# Process both train and test datasets\n",
    "process_dataset(train_dir, \"train\")\n",
    "process_dataset(test_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"hff_features_train.npy\")\n",
    "y_train = np.load(\"hff_labels_train.npy\")\n",
    "X_test = np.load(\"hff_features_test.npy\")\n",
    "y_test = np.load(\"hff_labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network Classifier\n",
    "class HFFClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(HFFClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(set(y_train.numpy()))\n",
    "model = HFFClassifier(input_size, num_classes)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.5902, Train Accuracy: 57.60%, Test Accuracy: 56.85%\n",
      "Epoch [2/30], Loss: 1.4832, Train Accuracy: 68.17%, Test Accuracy: 73.31%\n",
      "Epoch [3/30], Loss: 1.4347, Train Accuracy: 73.12%, Test Accuracy: 72.05%\n",
      "Epoch [4/30], Loss: 1.4298, Train Accuracy: 73.72%, Test Accuracy: 74.52%\n",
      "Epoch [5/30], Loss: 1.4148, Train Accuracy: 74.98%, Test Accuracy: 69.19%\n",
      "Epoch [6/30], Loss: 1.4005, Train Accuracy: 76.49%, Test Accuracy: 77.69%\n",
      "Epoch [7/30], Loss: 1.4035, Train Accuracy: 76.12%, Test Accuracy: 76.65%\n",
      "Epoch [8/30], Loss: 1.4015, Train Accuracy: 76.35%, Test Accuracy: 76.95%\n",
      "Epoch [9/30], Loss: 1.3921, Train Accuracy: 77.20%, Test Accuracy: 76.86%\n",
      "Epoch [10/30], Loss: 1.3771, Train Accuracy: 78.81%, Test Accuracy: 78.90%\n",
      "Epoch [11/30], Loss: 1.3809, Train Accuracy: 78.47%, Test Accuracy: 77.47%\n",
      "Epoch [12/30], Loss: 1.3706, Train Accuracy: 79.45%, Test Accuracy: 80.16%\n",
      "Epoch [13/30], Loss: 1.3643, Train Accuracy: 80.19%, Test Accuracy: 73.66%\n",
      "Epoch [14/30], Loss: 1.3720, Train Accuracy: 79.32%, Test Accuracy: 78.55%\n",
      "Epoch [15/30], Loss: 1.3601, Train Accuracy: 80.54%, Test Accuracy: 78.60%\n",
      "Epoch [16/30], Loss: 1.3579, Train Accuracy: 80.67%, Test Accuracy: 79.64%\n",
      "Epoch [17/30], Loss: 1.3594, Train Accuracy: 80.47%, Test Accuracy: 77.86%\n",
      "Epoch [18/30], Loss: 1.3570, Train Accuracy: 80.83%, Test Accuracy: 79.94%\n",
      "Epoch [19/30], Loss: 1.3506, Train Accuracy: 81.38%, Test Accuracy: 80.07%\n",
      "Epoch [20/30], Loss: 1.3740, Train Accuracy: 79.08%, Test Accuracy: 80.37%\n",
      "Epoch [21/30], Loss: 1.3505, Train Accuracy: 81.38%, Test Accuracy: 79.81%\n",
      "Epoch [22/30], Loss: 1.3390, Train Accuracy: 82.54%, Test Accuracy: 78.55%\n",
      "Epoch [23/30], Loss: 1.3390, Train Accuracy: 82.54%, Test Accuracy: 83.54%\n",
      "Epoch [24/30], Loss: 1.3149, Train Accuracy: 85.05%, Test Accuracy: 84.06%\n",
      "Epoch [25/30], Loss: 1.3038, Train Accuracy: 86.17%, Test Accuracy: 84.23%\n",
      "Epoch [26/30], Loss: 1.3096, Train Accuracy: 85.54%, Test Accuracy: 80.98%\n",
      "Epoch [27/30], Loss: 1.3075, Train Accuracy: 85.76%, Test Accuracy: 85.01%\n",
      "Epoch [28/30], Loss: 1.3052, Train Accuracy: 85.92%, Test Accuracy: 82.54%\n",
      "Epoch [29/30], Loss: 1.2887, Train Accuracy: 87.62%, Test Accuracy: 86.18%\n",
      "Epoch [30/30], Loss: 1.2817, Train Accuracy: 88.32%, Test Accuracy: 86.53%\n",
      "✅ Training Completed!\n",
      "✅ Model Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "        total_train += targets.size(0)\n",
    "\n",
    "    train_accuracy = correct_train / total_train * 100  # Train Accuracy %\n",
    "\n",
    "    # Evaluation phase (Test Accuracy)\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_test += (predicted == targets).sum().item()\n",
    "            total_test += targets.size(0)\n",
    "\n",
    "    test_accuracy = correct_test / total_test * 100  # Test Accuracy %\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"✅ Training Completed!\")\n",
    "\n",
    "# Save Model\n",
    "torch.save(model.state_dict(), \"hff_model.pth\")\n",
    "print(\"✅ Model Saved Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Accuracy: 86.53%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate Model\n",
    "model.eval()\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predictions = torch.argmax(outputs, dim=1).numpy()\n",
    "        y_pred.extend(predictions)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_test.numpy(), np.array(y_pred))\n",
    "print(f\"✅ Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "majorproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
